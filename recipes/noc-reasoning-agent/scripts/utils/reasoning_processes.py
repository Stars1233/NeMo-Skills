# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Auto-generated reasoning processes for all 70 workflows.
Maps fault_category (workflow ID) -> SOP text for use in formatting_prompt.yaml.

Generated by: scripts/utils/generate_reasoning_processes.py
"""

WORKFLOW_REASONING_PROCESSES = {
    "compute_certificate_renewal": """
    Workflow: Certificate Expiry Resolution
    Domain: COMPUTE | Problem Codes: CMP-012 | SLA: 60 minutes
    Description: TLS/SSL certificate expiry detection and renewal

    1. Verify Certificate Alarm: Confirm certificate expiration
        - Tools Used: query_alarm()
        - Expected Outcomes: Certificate expired; Certificate expiring soon; TLS handshake failing
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Identify Affected Services: List services using the certificate
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Services identified; Multiple certs affected
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Trigger Certificate Renewal: Request new certificate from CA
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Certificate renewed; Renewal in progress; Manual renewal needed
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Deploy New Certificate: Update secrets and restart services
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Certificate deployed; Services updated
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Escalate Certificate Issue: Create ticket for security team
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Security team notified
        - Flow: Proceed to step 6.

    6. Verify TLS Connectivity: Confirm TLS working with new cert
        - Tools Used: verify_recovery()
        - Expected Outcomes: TLS healthy; Certificate valid; Renewal complete
        - Flow: Proceed to step end.

    """,
    "compute_cnf_pod_recovery": """
    Workflow: CNF Pod Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-006 | SLA: 15 minutes
    Description: Cloud Native Function pod failure recovery

    1. Verify CNF Alarm: Confirm CNF pod failure
        - Tools Used: query_alarm()
        - Expected Outcomes: CNF pod crashed; CNF not ready; CNF degraded
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check CNF Pod Status: Query CNF pod and container state
        - Tools Used: query_container_status()
        - Expected Outcomes: Pod CrashLoopBackOff; Init failed; Liveness probe failing
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check CNF Logs: Review CNF application logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: License error; Configuration error; Database connection failed
        - Flow: Proceed to step 4.

    4. Check Dependent Services: Verify CNF dependencies available
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Dependencies OK; Database down; Message bus unavailable
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Restart CNF Pod: Delete and recreate CNF pod
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: CNF restarting; CNF scheduled; Restart failed
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Trigger CNF Failover: Activate standby CNF instance
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Failover successful; Standby activated
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to CNF Vendor: Create critical ticket for vendor support
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Vendor support engaged
        - Flow: Proceed to step 8.

    8. Verify CNF Recovery: Confirm CNF operational
        - Tools Used: verify_recovery()
        - Expected Outcomes: CNF healthy; Running on standby; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "compute_container_crash_recovery": """
    Workflow: Container Crash Recovery
    Domain: COMPUTE | Problem Codes: CMP-002 | SLA: 30 minutes
    Description: Container/pod crash loop detection and recovery

    1. Verify Container Alarm: Confirm container crash or restart loop
        - Tools Used: query_alarm()
        - Expected Outcomes: CrashLoopBackOff; Container OOMKilled; Container Error
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Pod Status: Query Kubernetes pod state
        - Tools Used: query_container_status()
        - Expected Outcomes: Pod CrashLoopBackOff; Pod Pending; Init containers failing
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Container Logs: Review container application logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: Application error; Configuration error; Dependency failure; OOM
        - Flow: Proceed to step 4.

    4. Check Resource Limits: Verify container resource allocation
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Memory limit hit; CPU throttled; Resources adequate
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Attempt Pod Restart: Delete and recreate pod
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Pod restarting; Pod scheduled; Restart failed
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Scale Replacement Pods: Scale deployment to create new pods
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Pods scaled; Healthy pods available
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to DevOps: Create ticket for application investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: DevOps team notified
        - Flow: Proceed to step 8.

    8. Verify Container Recovery: Confirm pod running and healthy
        - Tools Used: verify_recovery()
        - Expected Outcomes: Pod healthy; Pod degraded; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "compute_image_pull_recovery": """
    Workflow: Image Pull Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-010 | SLA: 30 minutes
    Description: Container image pull failure resolution

    1. Verify Image Pull Alarm: Confirm image pull failure
        - Tools Used: query_alarm()
        - Expected Outcomes: ImagePullBackOff; ErrImagePull; Registry timeout
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Registry Connectivity: Test connectivity to container registry
        - Tools Used: test_connectivity()
        - Expected Outcomes: Registry unreachable; Auth failure; Rate limited
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Verify Image Credentials: Check image pull secrets
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Credentials valid; Credentials expired; Secret missing
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Registry Fix: Update credentials or switch registry
        - Tools Used: apply_configuration()
        - Expected Outcomes: Credentials updated; Registry switched
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Escalate Registry Issue: Create ticket for registry team
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: DevOps team notified
        - Flow: Proceed to step 6.

    6. Verify Image Pull: Confirm pods scheduling successfully
        - Tools Used: verify_recovery()
        - Expected Outcomes: Images pulling; Pods scheduled; Issue resolved
        - Flow: Proceed to step end.

    """,
    "compute_k8s_node_recovery": """
    Workflow: Kubernetes Node Recovery
    Domain: COMPUTE | Problem Codes: CMP-003 | SLA: 30 minutes
    Description: K8s node NotReady state recovery

    1. Verify Node Alarm: Confirm Kubernetes node NotReady
        - Tools Used: query_alarm()
        - Expected Outcomes: Node NotReady; Node unschedulable; Kubelet not responding
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check Node Status: Query Kubernetes node conditions
        - Tools Used: query_container_status()
        - Expected Outcomes: MemoryPressure; DiskPressure; PIDPressure; NetworkUnavailable
        - Flow: If succeeds, go to step 3; if fails, go to step 7.

    3. Check Node Resources: Verify node CPU/memory/disk
        - Tools Used: query_resource_health()
        - Expected Outcomes: Resources exhausted; Resources OK; Disk full
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Kubelet Status: Verify kubelet service running
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Kubelet stopped; Kubelet crashlooping; Certificate expired
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Restart Kubelet: Restart kubelet service on node
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Kubelet restarted; Node recovering; Restart failed
        - Flow: If succeeds, go to step 9; if fails, go to step 6.

    6. Drain Node: Cordon and drain unhealthy node
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Node drained; Pods rescheduled; Some pods stuck
        - Flow: Proceed to step 7.

    7. Reboot Node: Reboot the failing node
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Node rebooting; Reboot initiated; Reboot failed
        - Flow: If succeeds, go to step 9; if fails, go to step 8.

    8. Escalate to Platform Team: Create ticket for node replacement
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Platform team engaged
        - Flow: Proceed to step 9.

    9. Verify Node Recovery: Confirm node Ready
        - Tools Used: verify_recovery()
        - Expected Outcomes: Node Ready; Node recovering; Node replacement needed
        - Flow: Proceed to step end.

    """,
    "compute_network_policy_recovery": """
    Workflow: Network Policy Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-011 | SLA: 30 minutes
    Description: K8s network policy misconfiguration resolution

    1. Verify Network Policy Alarm: Confirm network policy blocking traffic
        - Tools Used: query_alarm()
        - Expected Outcomes: Traffic blocked; Pod isolation; Ingress denied
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Analyze Network Policies: Review active network policies
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Restrictive policy found; Missing allow rule; Label mismatch
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Test Pod Connectivity: Verify pod-to-pod and pod-to-service connectivity
        - Tools Used: test_connectivity()
        - Expected Outcomes: Connectivity blocked; Partial connectivity; DNS issues
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Policy Correction: Update or remove blocking network policy
        - Tools Used: apply_configuration()
        - Expected Outcomes: Policy updated; Allow rule added
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Escalate to Security Team: Create ticket for policy review
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Security team notified
        - Flow: Proceed to step 6.

    6. Verify Network Connectivity: Confirm traffic flowing correctly
        - Tools Used: verify_recovery()
        - Expected Outcomes: Connectivity restored; Policy adjusted; Review ongoing
        - Flow: Proceed to step end.

    """,
    "compute_orchestrator_recovery": """
    Workflow: Orchestrator Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-005 | SLA: 15 minutes
    Description: Container/VM orchestrator failure recovery

    1. Verify Orchestrator Alarm: Confirm orchestrator health issue
        - Tools Used: query_alarm()
        - Expected Outcomes: API server down; etcd unhealthy; Controller failure
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Control Plane: Verify control plane component status
        - Tools Used: query_container_status()
        - Expected Outcomes: API server unhealthy; Scheduler down; etcd quorum lost
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check etcd Cluster: Verify etcd cluster health
        - Tools Used: run_diagnostics()
        - Expected Outcomes: etcd healthy; etcd degraded; etcd split brain
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Restart Control Plane: Restart failed control plane components
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Control plane recovering; Restart in progress; Restart failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Recover etcd: Restore etcd from backup if needed
        - Tools Used: execute_remote_action()
        - Expected Outcomes: etcd recovered; Restore from backup; Manual intervention needed
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Failover to Backup Control Plane: Switch to backup orchestrator
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Backup active
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to Platform Team: Create critical ticket for orchestrator recovery
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Platform team engaged
        - Flow: Proceed to step 8.

    8. Verify Orchestrator Recovery: Confirm orchestrator healthy
        - Tools Used: verify_recovery()
        - Expected Outcomes: Orchestrator healthy; Running on backup; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "compute_resource_exhaustion_resolution": """
    Workflow: Resource Exhaustion Resolution
    Domain: COMPUTE | Problem Codes: CMP-008 | SLA: 30 minutes
    Description: Compute resource exhaustion detection and mitigation

    1. Verify Resource Alarm: Confirm resource exhaustion
        - Tools Used: query_alarm()
        - Expected Outcomes: CPU exhausted; Memory exhausted; Disk full
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Analyze Resource Usage: Identify resource consumption by workload
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Specific workload identified; General overload; Resource leak
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Apply Resource Limits: Enforce or adjust resource quotas
        - Tools Used: apply_configuration()
        - Expected Outcomes: Limits applied; Quota enforced
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Scale Resources: Add compute capacity or scale workloads
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Resources scaled; Capacity added; Scaling limited
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Terminate Non-Critical Workloads: Stop low priority workloads to free resources
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Workloads terminated; Resources freed
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Request Capacity Expansion: Create ticket for infrastructure expansion
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Capacity request submitted
        - Flow: Proceed to step 7.

    7. Verify Resource Status: Monitor resource utilization
        - Tools Used: verify_recovery()
        - Expected Outcomes: Resources normalized; Resources stable; Expansion in progress
        - Flow: Proceed to step end.

    """,
    "compute_service_mesh_recovery": """
    Workflow: Service Mesh Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-009 | SLA: 30 minutes
    Description: Service mesh control/data plane failure recovery

    1. Verify Mesh Alarm: Confirm service mesh issue
        - Tools Used: query_alarm()
        - Expected Outcomes: Control plane unhealthy; Sidecar failures; mTLS errors
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check Mesh Control Plane: Verify Istio/Linkerd control plane status
        - Tools Used: query_container_status()
        - Expected Outcomes: istiod unhealthy; Pilot not syncing; Control plane overloaded
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Sidecar Proxies: Verify sidecar proxy health across pods
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Sidecars healthy; Sidecars crashing; Config sync failed
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Restart Mesh Control Plane: Restart mesh control plane components
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Control plane restarted; Mesh recovering
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Rollback Mesh Configuration: Restore previous mesh configuration
        - Tools Used: apply_configuration()
        - Expected Outcomes: Config rolled back; Previous config restored
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to Platform Team: Create ticket for mesh investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Platform team notified
        - Flow: Proceed to step 7.

    7. Verify Mesh Recovery: Confirm service mesh healthy
        - Tools Used: verify_recovery()
        - Expected Outcomes: Mesh healthy; Mesh recovering; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "compute_storage_failure_recovery": """
    Workflow: Storage Volume Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-004 | SLA: 30 minutes
    Description: Persistent storage volume failure recovery

    1. Verify Storage Alarm: Confirm storage volume failure
        - Tools Used: query_alarm()
        - Expected Outcomes: Volume unavailable; Mount failed; I/O errors
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Volume Status: Query storage backend status
        - Tools Used: query_resource_health()
        - Expected Outcomes: Volume degraded; Volume offline; Backend unreachable
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Storage Backend: Verify storage array health
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Backend healthy; Backend degraded; Path failure
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Attempt Volume Recovery: Force remount or reconnect volume
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Volume recovered; Remount successful; Recovery failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Failover to Replica: Switch to storage replica if available
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Failover successful; No replica available
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Restart Dependent Workloads: Restart pods/VMs using the volume
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Workloads restarted; Some workloads pending
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to Storage Team: Create critical ticket for storage repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Storage team engaged
        - Flow: Proceed to step 8.

    8. Verify Storage Recovery: Confirm volume accessible
        - Tools Used: verify_recovery()
        - Expected Outcomes: Storage recovered; Degraded mode; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "compute_vm_failure_recovery": """
    Workflow: VM Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-001 | SLA: 30 minutes
    Description: Virtual machine failure detection and recovery

    1. Verify VM Alarm: Confirm VM failure or unreachable
        - Tools Used: query_alarm()
        - Expected Outcomes: VM unreachable; VM crashed; VM heartbeat lost
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check Hypervisor Status: Verify host hypervisor health
        - Tools Used: query_resource_health()
        - Expected Outcomes: Hypervisor healthy; Hypervisor overloaded; Hypervisor fault
        - Flow: If succeeds, go to step 3; if fails, go to step 7.

    3. Check VM Status: Query VM state from orchestrator
        - Tools Used: query_container_status()
        - Expected Outcomes: VM error state; VM paused; VM stopped; VM not found
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Check VM Logs: Review VM console and system logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: Kernel panic; Out of memory; Disk full; Application crash
        - Flow: Proceed to step 5.

    5. Attempt VM Restart: Restart the failed VM
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: VM restarting; VM started; Restart failed
        - Flow: If succeeds, go to step 9; if fails, go to step 6.

    6. Attempt VM Migration: Live migrate VM to healthy host
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Migration successful; Migration in progress; Migration failed
        - Flow: If succeeds, go to step 9; if fails, go to step 7.

    7. Restore from Snapshot: Recover VM from last known good snapshot
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Restore successful; Snapshot not available
        - Flow: If succeeds, go to step 9; if fails, go to step 8.

    8. Escalate to Cloud Team: Create critical ticket for cloud operations
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Cloud team engaged
        - Flow: Proceed to step 9.

    9. Verify VM Recovery: Confirm VM operational
        - Tools Used: verify_recovery()
        - Expected Outcomes: VM recovered; VM degraded; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "compute_vnf_failure_recovery": """
    Workflow: VNF Failure Recovery
    Domain: COMPUTE | Problem Codes: CMP-007 | SLA: 30 minutes
    Description: Virtual Network Function failure recovery

    1. Verify VNF Alarm: Confirm VNF failure
        - Tools Used: query_alarm()
        - Expected Outcomes: VNF unreachable; VNF degraded; VNF heartbeat lost
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check VNF Status: Query VNF manager for instance state
        - Tools Used: query_resource_health()
        - Expected Outcomes: VNF error; VNF stopped; VNF overloaded
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check VNF Logs: Review VNF application logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: Software crash; Resource exhaustion; License issue
        - Flow: Proceed to step 4.

    4. Attempt VNF Restart: Restart VNF via VNFM
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: VNF restarting; VNF started; Restart failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Scale Out VNF: Create new VNF instance for redundancy
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Scale out successful; New instance created
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Activate Geo-Redundant VNF: Failover to secondary site VNF
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Geo-failover initiated; Secondary VNF active
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to VNF Vendor: Create critical ticket for vendor support
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Vendor support engaged
        - Flow: Proceed to step 8.

    8. Verify VNF Recovery: Confirm VNF operational
        - Tools Used: verify_recovery()
        - Expected Outcomes: VNF healthy; Running on secondary; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "core_charging_failure_recovery": """
    Workflow: Charging System Failure Recovery
    Domain: CORE | Problem Codes: CORE-005 | SLA: 30 minutes
    Description: Online/offline charging system failure recovery

    1. Verify Charging Alarm: Confirm charging system failure
        - Tools Used: query_alarm()
        - Expected Outcomes: OCS unreachable; CDR generation failed; Rating error
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check Charging Status: Query charging system health
        - Tools Used: query_resource_health()
        - Expected Outcomes: OCS fault; Mediation backup; Database issue
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Gy/N40 Interface: Verify charging signaling path
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Interface healthy; Timeout; Connection lost
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Enable Offline Charging Fallback: Switch to offline charging if OCS down
        - Tools Used: apply_configuration()
        - Expected Outcomes: Fallback enabled; CDR buffering active
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Failover to Backup OCS: Switch to backup charging system
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Backup OCS active
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to Billing Team: Create ticket for charging system repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Billing team engaged
        - Flow: Proceed to step 7.

    7. Verify Charging Recovery: Confirm charging services restored
        - Tools Used: verify_recovery()
        - Expected Outcomes: Charging recovered; Running on fallback; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "core_gateway_failure_recovery": """
    Workflow: SGW/PGW/UPF Failure Recovery
    Domain: CORE | Problem Codes: CORE-002 | SLA: 15 minutes
    Description: User plane gateway failure detection and recovery

    1. Verify Gateway Alarm: Confirm SGW/PGW/UPF failure
        - Tools Used: query_alarm()
        - Expected Outcomes: Gateway unreachable; GTP path failure; User plane down
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check Gateway Status: Query gateway health and session state
        - Tools Used: query_resource_health()
        - Expected Outcomes: Gateway fault; Processing overload; Interface down
        - Flow: If succeeds, go to step 3; if fails, go to step 7.

    3. Check GTP Paths: Verify GTP tunnel status
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: GTP-C path down; GTP-U path down; Echo timeout
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Attempt Gateway Restart: Restart gateway service
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Gateway restarting; Service recovery; Restart failed
        - Flow: If succeeds, go to step 9; if fails, go to step 5.

    5. Trigger Gateway Failover: Activate standby gateway
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Standby activated; Sessions migrating
        - Flow: If succeeds, go to step 9; if fails, go to step 6.

    6. Redirect Traffic: Update routing to bypass failed gateway
        - Tools Used: apply_configuration()
        - Expected Outcomes: Traffic rerouted; Alternate path active
        - Flow: If succeeds, go to step 9; if fails, go to step 7.

    7. Notify Affected Services: Alert dependent services of gateway failure
        - Tools Used: query_external_factors()
        - Expected Outcomes: Services notified; Impact assessed
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Escalate to Core Team: Create critical ticket for gateway repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team engaged
        - Flow: Proceed to step 9.

    9. Verify Gateway Recovery: Confirm gateway operational
        - Tools Used: verify_recovery()
        - Expected Outcomes: Gateway recovered; Running on standby; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "core_hss_udm_recovery": """
    Workflow: HSS/UDM Unavailability Recovery
    Domain: CORE | Problem Codes: CORE-003 | SLA: 15 minutes
    Description: Subscriber database unavailability recovery

    1. Verify HSS/UDM Alarm: Confirm HSS or UDM unavailable
        - Tools Used: query_alarm()
        - Expected Outcomes: HSS unreachable; UDM not responding; Database timeout
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check HSS/UDM Status: Query subscriber database health
        - Tools Used: query_resource_health()
        - Expected Outcomes: Database fault; Overloaded; Replication lag
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Diameter Connectivity: Verify Diameter path to HSS/UDM
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Diameter healthy; Diameter timeout; DRA congested
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt HSS Recovery: Restart HSS/UDM service
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Service restarting; Database recovering; Restart failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Failover to Backup HSS: Switch to geo-redundant HSS/UDM
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Backup HSS active
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Enable Local Cache: Activate cached subscriber data if available
        - Tools Used: apply_configuration()
        - Expected Outcomes: Cache enabled; Limited service available
        - Flow: Proceed to step 7.
        - Note: This step is skippable if not applicable.

    7. Escalate to Core Database Team: Create critical ticket for HSS/UDM repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Database team engaged
        - Flow: Proceed to step 8.

    8. Verify HSS/UDM Recovery: Confirm subscriber services restored
        - Tools Used: verify_recovery()
        - Expected Outcomes: HSS recovered; Running on backup; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "core_mme_amf_overload_mitigation": """
    Workflow: MME/AMF Overload Mitigation
    Domain: CORE | Problem Codes: CORE-001 | SLA: 15 minutes
    Description: Core mobility management overload detection and mitigation

    1. Verify MME/AMF Alarm: Confirm MME or AMF overload condition
        - Tools Used: query_alarm()
        - Expected Outcomes: CPU overload; Memory high; Session capacity exceeded; Signaling storm
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Node Status: Query MME/AMF operational metrics
        - Tools Used: query_resource_health()
        - Expected Outcomes: CPU >80%; Sessions near limit; Message queue building
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Analyze Traffic Pattern: Identify source of overload
        - Tools Used: query_performance()
        - Expected Outcomes: Attach storm detected; Paging flood; Normal peak traffic; Single eNB causing load
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Enable Overload Controls: Activate NAS-level overload controls
        - Tools Used: apply_configuration()
        - Expected Outcomes: Overload control active; Attach rejection enabled; Paging optimization active
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Redistribute Load: Trigger S1-flex load redistribution
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Load redistributed; eNBs rebalanced; Pool weight adjusted
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Scale Out MME/AMF: Activate standby instance or scale capacity
        - Tools Used: orchestrate_workload()
        - Expected Outcomes: Instance scaled; Capacity added
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to Core Team: Create critical ticket for core operations
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team engaged
        - Flow: Proceed to step 8.

    8. Verify Load Status: Monitor MME/AMF load recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Load normalized; Overload controlled; Capacity added
        - Flow: Proceed to step end.

    """,
    "core_pcrf_pcf_recovery": """
    Workflow: PCRF/PCF Failure Recovery
    Domain: CORE | Problem Codes: CORE-004 | SLA: 30 minutes
    Description: Policy control function failure recovery

    1. Verify PCRF/PCF Alarm: Confirm policy function failure
        - Tools Used: query_alarm()
        - Expected Outcomes: PCRF unreachable; PCF timeout; Policy rule failure
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check PCRF/PCF Status: Query policy engine health
        - Tools Used: query_resource_health()
        - Expected Outcomes: Service fault; Database issue; Overloaded
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Gx/N7 Interface: Verify policy signaling path
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Interface healthy; Diameter timeout; Connection refused
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Restart PCRF/PCF Service: Restart policy control service
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Service restarting; Service recovered; Restart failed
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Failover to Backup PCRF: Switch to standby policy engine
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Backup active
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to Policy Team: Create ticket for policy function repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Policy team engaged
        - Flow: Proceed to step 7.

    7. Verify Policy Recovery: Confirm policy services restored
        - Tools Used: verify_recovery()
        - Expected Outcomes: PCRF recovered; Running on backup; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "env_battery_temperature_response": """
    Workflow: Battery High Temperature Response
    Domain: POWER | Problem Codes: ENV-006 | SLA: 30 minutes
    Description: Battery thermal runaway prevention and mitigation

    1. Verify Battery Temperature Alarm: Confirm battery temperature reading
        - Tools Used: query_alarm()
        - Expected Outcomes: Battery temp elevated; Battery temp critical; Multiple strings affected
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Battery Status: Get detailed battery temperature and charge state
        - Tools Used: query_power_system()
        - Expected Outcomes: Temp 35-40C - elevated; Temp 40-45C - high; Temp >45C - critical
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check HVAC Cooling: Verify battery room cooling operational
        - Tools Used: query_power_system()
        - Expected Outcomes: HVAC running - cooling active; HVAC fault detected; HVAC capacity insufficient
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Reduce Charge Rate: Lower rectifier charge current to reduce heat
        - Tools Used: apply_configuration()
        - Expected Outcomes: Charge rate reduced; Already at minimum; Configuration applied
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Increase Battery Room Cooling: Maximize cooling to battery area
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Emergency cooling activated; Cooling already maximum; Cooling system fault
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Isolate Battery String: Disconnect affected battery string if critical
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Battery string isolated; Isolation not possible remotely
        - Flow: Proceed to step 7.

    7. Emergency Dispatch: Dispatch technician for battery inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Emergency dispatch initiated
        - Flow: Proceed to step 8.

    8. Monitor Battery Temperature: Track temperature trend
        - Tools Used: verify_recovery()
        - Expected Outcomes: Temperature declining; Temperature stabilized; Temperature still rising
        - Flow: Proceed to step end.

    """,
    "env_cabinet_intrusion_response": """
    Workflow: Cabinet Intrusion Response
    Domain: POWER | Problem Codes: ENV-005 | SLA: 30 minutes
    Description: Security breach detection and response

    1. Verify Intrusion Alarm: Confirm cabinet door or tamper alarm
        - Tools Used: query_alarm()
        - Expected Outcomes: Door open alarm; Tamper detected; Multiple cabinets alarming
        - Flow: If succeeds, go to step 2; if fails, go to step 4.

    2. Check Scheduled Maintenance: Verify if maintenance window is active
        - Tools Used: query_external_factors()
        - Expected Outcomes: Scheduled work in progress; No scheduled work; Maintenance window ended
        - Flow: If succeeds, go to step 5; if fails, go to step 3.

    3. Verify Site Access Log: Check recent access control entries
        - Tools Used: inspect_logs()
        - Expected Outcomes: Authorized access logged; Unauthorized access suspected; Access log unavailable
        - Flow: Proceed to step 4.

    4. Create Security Incident: Log security event and dispatch if unauthorized
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Security incident logged; Field verification dispatched
        - Flow: Proceed to step 5.

    5. Monitor Cabinet Status: Verify cabinet status and equipment health
        - Tools Used: verify_recovery()
        - Expected Outcomes: Cabinet secured; Door still open; Equipment status verified
        - Flow: Proceed to step end.

    """,
    "env_high_temperature_response": """
    Workflow: High Temperature Alert Response
    Domain: POWER | Problem Codes: ENV-001 | SLA: 60 minutes
    Description: Site overheating diagnosis and mitigation

    1. Verify Temperature Alarm: Confirm high temperature reading and affected zone
        - Tools Used: query_alarm()
        - Expected Outcomes: High temp confirmed; Temperature sensor spike; Multiple zones affected
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Current Temperature: Get detailed temperature readings
        - Tools Used: query_power_system()
        - Expected Outcomes: Temp elevated but manageable; Temp approaching critical; Temp critical - equipment at risk
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Verify HVAC Operation: Check cooling system status
        - Tools Used: query_power_system()
        - Expected Outcomes: HVAC running normally; HVAC fault detected; HVAC capacity insufficient
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Adjust HVAC Settings: Increase cooling or enable emergency mode
        - Tools Used: apply_configuration()
        - Expected Outcomes: Cooling increased; Already at maximum; Configuration applied
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Attempt HVAC Reset: Restart HVAC controller
        - Tools Used: execute_remote_action()
        - Expected Outcomes: HVAC restarted successfully; HVAC failed to restart
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Implement Load Reduction: Reduce equipment load to lower heat output
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Non-critical equipment powered down; Load reduction limited
        - Flow: Proceed to step 7.

    7. Dispatch HVAC Service: Create work order for HVAC repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: HVAC service dispatched
        - Flow: Proceed to step 8.

    8. Monitor Temperature Trend: Verify temperature stabilizing or declining
        - Tools Used: verify_recovery()
        - Expected Outcomes: Temperature stabilizing; Temperature declining; Temperature still rising
        - Flow: Proceed to step end.

    """,
    "env_humidity_threshold_response": """
    Workflow: Humidity Threshold Response
    Domain: POWER | Problem Codes: ENV-004 | SLA: 120 minutes
    Description: High humidity detection and correction

    1. Verify Humidity Alarm: Confirm humidity level and affected area
        - Tools Used: query_alarm()
        - Expected Outcomes: Humidity elevated; Humidity critical; Sensor fault suspected
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Environmental Readings: Get current temperature and humidity values
        - Tools Used: query_power_system()
        - Expected Outcomes: Humidity 60-70% - elevated; Humidity >70% - high; Humidity normalizing
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Adjust HVAC Dehumidification: Enable or increase dehumidification mode
        - Tools Used: apply_configuration()
        - Expected Outcomes: Dehumidification enabled; Already at maximum; HVAC adjustment applied
        - Flow: If succeeds, go to step 5; if fails, go to step 4.

    4. Schedule HVAC Inspection: Create work order for HVAC inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Inspection scheduled
        - Flow: Proceed to step 5.
        - Note: This step is skippable if not applicable.

    5. Verify Humidity Stabilizing: Monitor humidity trend
        - Tools Used: verify_recovery()
        - Expected Outcomes: Humidity declining; Humidity stable; Humidity still elevated
        - Flow: Proceed to step end.

    """,
    "env_hvac_fault_recovery": """
    Workflow: HVAC System Fault Recovery
    Domain: POWER | Problem Codes: ENV-002 | SLA: 90 minutes
    Description: HVAC failure diagnosis and recovery

    1. Verify HVAC Alarm: Confirm HVAC fault type and affected units
        - Tools Used: query_alarm()
        - Expected Outcomes: Compressor fault; Fan failure; Refrigerant issue; Control fault
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check HVAC Status: Query HVAC controller for detailed diagnostics
        - Tools Used: query_power_system()
        - Expected Outcomes: Single unit failed - redundancy OK; Multiple units affected; Primary cooling lost
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Attempt HVAC Reset: Reset HVAC controller and compressor
        - Tools Used: execute_remote_action()
        - Expected Outcomes: HVAC recovered; Reset failed; Temporary recovery
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Verify Cooling Restored: Confirm cooling output restored
        - Tools Used: query_power_system()
        - Expected Outcomes: Cooling restored to normal; Partial cooling; Cooling insufficient
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Enable Backup Cooling: Activate emergency/backup cooling if available
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Backup cooling activated; No backup available
        - Flow: Proceed to step 6.
        - Note: This step is skippable if not applicable.

    6. Dispatch HVAC Technician: Schedule HVAC repair service
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: HVAC technician dispatched
        - Flow: Proceed to step 7.

    7. Verify Environmental Status: Confirm temperature and humidity acceptable
        - Tools Used: verify_recovery()
        - Expected Outcomes: Environment within limits; Temperature elevated but stable; Continued monitoring required
        - Flow: Proceed to step end.

    """,
    "env_water_intrusion_response": """
    Workflow: Water Intrusion Response
    Domain: POWER | Problem Codes: ENV-003 | SLA: 30 minutes
    Description: Water leak detection and emergency response

    1. Verify Water Detection Alarm: Confirm water intrusion and location
        - Tools Used: query_alarm()
        - Expected Outcomes: Water detected - floor sensor; Water detected - ceiling sensor; Multiple sensors triggered
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Assess Equipment Risk: Identify equipment at risk from water damage
        - Tools Used: query_resource_health()
        - Expected Outcomes: Equipment clear of water; Equipment at risk; Equipment already affected
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Check for HVAC Condensation: Determine if HVAC is source of water
        - Tools Used: query_power_system()
        - Expected Outcomes: HVAC drain blocked; HVAC condensation normal; External water source
        - Flow: Proceed to step 4.
        - Note: This step is skippable if not applicable.

    4. Initiate Emergency Protection: Isolate affected circuits if necessary
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Circuits isolated for safety; No isolation needed; Isolation failed
        - Flow: Proceed to step 5.

    5. Emergency Dispatch: Dispatch technician for water mitigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Emergency dispatch initiated
        - Flow: Proceed to step 6.

    6. Monitor Site Status: Continue monitoring for further water ingress
        - Tools Used: verify_recovery()
        - Expected Outcomes: Situation contained; Water spreading; Equipment impact reported
        - Flow: Proceed to step end.

    """,
    "power_ac_failure_recovery": """
    Workflow: AC Power Failure Recovery
    Domain: POWER | Problem Codes: PWR-001 | SLA: 60 minutes
    Description: Complete AC power failure response including UPS/generator verification

    1. Verify AC Power Loss: Confirm AC mains failure on affected site
        - Tools Used: query_alarm()
        - Expected Outcomes: AC loss confirmed; Partial AC loss; Transient spike only
        - Flow: If succeeds, go to step 2; if fails, go to step end.

    2. Check UPS Status: Verify UPS engaged and battery capacity
        - Tools Used: query_power_system()
        - Expected Outcomes: UPS active - load transferred; UPS battery low; UPS failed
        - Flow: If succeeds, go to step 3; if fails, go to step 8.

    3. Verify Battery Runtime: Assess remaining battery runtime and load
        - Tools Used: query_power_system()
        - Expected Outcomes: Runtime >60 min; Runtime 30-60 min; Runtime <30 min critical
        - Flow: If succeeds, go to step 4; if fails, go to step 8.

    4. Initiate Generator Start: Trigger backup generator startup sequence
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Generator started successfully; Generator start failed; Generator already running
        - Flow: If succeeds, go to step 5; if fails, go to step 8.

    5. Monitor Generator Stabilization: Wait for generator to reach stable output
        - Tools Used: query_power_system()
        - Expected Outcomes: Generator stable - ready for transfer; Generator unstable; Generator fault
        - Flow: If succeeds, go to step 6; if fails, go to step 8.

    6. Transfer Load to Generator: Execute automatic transfer switch to generator power
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Load transferred to generator; Transfer failed; Partial transfer
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Verify Site Power Restored: Confirm all equipment powered and operational
        - Tools Used: query_resource_health()
        - Expected Outcomes: All systems powered; Partial restoration; Some equipment failed to restart
        - Flow: If succeeds, go to step 9; if fails, go to step 8.

    8. Dispatch Field Technician: Create emergency dispatch for power restoration
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field dispatch created; Dispatch queued
        - Flow: If succeeds, go to step 9; if fails, go to step 10.

    9. Notify Utility Provider: Report outage to electric utility for restoration ETA
        - Tools Used: query_external_factors()
        - Expected Outcomes: Utility aware - ETA provided; Utility not reachable; Known area outage
        - Flow: Proceed to step 10.
        - Note: This step is skippable if not applicable.

    10. Final Verification: Verify service continuity and power status
        - Tools Used: verify_recovery()
        - Expected Outcomes: Site operational on backup power; Site degraded; Service impact ongoing
        - Flow: Proceed to step end.

    """,
    "power_battery_discharge_response": """
    Workflow: Battery Discharge Alert Response
    Domain: POWER | Problem Codes: PWR-003 | SLA: 30 minutes
    Description: Urgent battery discharge investigation and mitigation

    1. Acknowledge Battery Alert: Verify battery discharge alarm and severity
        - Tools Used: query_alarm()
        - Expected Outcomes: Battery discharging confirmed; Low voltage warning; Critical discharge rate
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check Battery Status: Get current battery level and discharge rate
        - Tools Used: query_power_system()
        - Expected Outcomes: Battery >50% - stable; Battery 20-50% - monitoring; Battery <20% - critical
        - Flow: If succeeds, go to step 3; if fails, go to step 8.

    3. Verify AC Power Status: Check if AC mains power is present
        - Tools Used: query_power_system()
        - Expected Outcomes: AC present - charging expected; AC absent - discharge expected; AC unstable
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Rectifier Charging: Verify rectifiers are charging batteries
        - Tools Used: query_power_system()
        - Expected Outcomes: Rectifiers charging batteries; Rectifier fault - not charging; Charge current low
        - Flow: If succeeds, go to step 9; if fails, go to step 5.

    5. Start Generator: Initiate backup generator for extended runtime
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Generator started - charging resumed; Generator failed to start
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Monitor Battery Recovery: Track battery voltage recovery
        - Tools Used: query_power_system()
        - Expected Outcomes: Battery voltage rising; Battery stable; Battery continues discharge
        - Flow: If succeeds, go to step 9; if fails, go to step 7.

    7. Implement Load Shedding: Reduce site load to extend battery runtime
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Non-critical loads shed; Load reduction limited
        - Flow: Proceed to step 8.

    8. Emergency Dispatch: Dispatch technician with portable generator
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Emergency dispatch initiated
        - Flow: Proceed to step 9.

    9. Verify Site Status: Confirm site operational status and power situation
        - Tools Used: verify_recovery()
        - Expected Outcomes: Site stable on backup; Site at risk; Controlled shutdown may be needed
        - Flow: Proceed to step end.

    """,
    "power_dc_rectifier_recovery": """
    Workflow: DC Rectifier Failure Recovery
    Domain: POWER | Problem Codes: PWR-002 | SLA: 120 minutes
    Description: DC rectifier fault diagnosis and recovery

    1. Confirm Rectifier Alarm: Verify rectifier failure alarm and identify affected unit
        - Tools Used: query_alarm()
        - Expected Outcomes: Rectifier fault confirmed; Intermittent fault; False alarm
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check DC Bus Voltage: Measure DC bus voltage and assess impact
        - Tools Used: query_power_system()
        - Expected Outcomes: DC voltage nominal with redundancy; DC voltage low; DC voltage critical
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Assess Rectifier Redundancy: Determine remaining rectifier capacity
        - Tools Used: query_power_system()
        - Expected Outcomes: N+1 redundancy maintained; Running at capacity; Below capacity threshold
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Attempt Rectifier Reset: Power cycle affected rectifier module
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Rectifier recovered; Reset failed; Rectifier hardware fault
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Verify Rectifier Recovery: Confirm rectifier back online and charging
        - Tools Used: query_power_system()
        - Expected Outcomes: Rectifier online - load sharing; Rectifier unstable; Rectifier failed
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Schedule Field Replacement: Create work order for rectifier replacement
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Work order created; Parts availability confirmed
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Enable Battery Monitoring: Set up enhanced battery monitoring during degraded state
        - Tools Used: apply_configuration()
        - Expected Outcomes: Enhanced monitoring enabled; Configuration applied
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Final Status Check: Verify power system stability
        - Tools Used: verify_recovery()
        - Expected Outcomes: System stable with redundancy; Operating in degraded mode; Escalation required
        - Flow: Proceed to step end.

    """,
    "power_generator_failure_recovery": """
    Workflow: Generator Failure Recovery
    Domain: POWER | Problem Codes: PWR-004 | SLA: 90 minutes
    Description: Backup generator fault diagnosis and recovery

    1. Verify Generator Alarm: Confirm generator failure or fault condition
        - Tools Used: query_alarm()
        - Expected Outcomes: Generator fault confirmed; Generator not starting; Generator running rough
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check Generator Status: Query generator controller for detailed status
        - Tools Used: query_power_system()
        - Expected Outcomes: Fuel level OK - electrical fault; Low fuel detected; Mechanical fault indicated
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Attempt Generator Reset: Reset generator controller and retry start
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Generator started after reset; Reset did not resolve issue
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Monitor Generator Stability: Verify generator running stable
        - Tools Used: query_power_system()
        - Expected Outcomes: Generator stable; Generator unstable
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Check Fuel Level: Verify fuel tank level and consumption rate
        - Tools Used: query_power_system()
        - Expected Outcomes: Fuel adequate; Fuel low - refuel needed; Fuel system fault
        - Flow: Proceed to step 6.
        - Note: This step is skippable if not applicable.

    6. Dispatch Generator Service: Create work order for generator repair/refuel
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Generator service dispatched; Fuel delivery scheduled
        - Flow: Proceed to step 7.

    7. Verify Backup Power Status: Confirm site power resilience status
        - Tools Used: verify_recovery()
        - Expected Outcomes: Generator operational; Site on UPS only - reduced backup; AC power restored
        - Flow: Proceed to step end.

    """,
    "ran_antenna_tilt_recovery": """
    Workflow: Antenna Tilt Fault Recovery
    Domain: RAN | Problem Codes: RAN-009 | SLA: 180 minutes
    Description: Remote electrical tilt (RET) fault recovery

    1. Verify Tilt Alarm: Confirm RET fault or incorrect tilt
        - Tools Used: query_alarm()
        - Expected Outcomes: RET communication fault; Tilt mismatch; RET motor fault
        - Flow: If succeeds, go to step 2; if fails, go to step 4.

    2. Check RET Controller: Query RET controller status
        - Tools Used: query_rf_status()
        - Expected Outcomes: RET controller offline; RET reporting incorrect tilt; RET motor stuck
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Attempt RET Reset: Reset RET controller
        - Tools Used: execute_remote_action()
        - Expected Outcomes: RET recovered; RET still faulty
        - Flow: If succeeds, go to step 5; if fails, go to step 4.

    4. Schedule Field Service: Create work order for RET repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field service scheduled
        - Flow: Proceed to step 5.

    5. Verify Coverage Impact: Assess impact of incorrect tilt
        - Tools Used: verify_recovery()
        - Expected Outcomes: Tilt corrected; Coverage stable; Field repair needed
        - Flow: Proceed to step end.

    """,
    "ran_backhaul_degradation_resolution": """
    Workflow: Backhaul Degradation Resolution
    Domain: RAN | Problem Codes: RAN-011 | SLA: 90 minutes
    Description: Backhaul performance degradation troubleshooting

    1. Verify Backhaul Alarm: Confirm backhaul performance issue
        - Tools Used: query_alarm()
        - Expected Outcomes: Bandwidth reduced; High latency; Packet loss detected; Link errors
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Test Backhaul Connectivity: Run connectivity tests on backhaul link
        - Tools Used: test_connectivity()
        - Expected Outcomes: Latency elevated; Packet loss confirmed; Throughput reduced
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Router Status: Query cell site router health
        - Tools Used: query_resource_health()
        - Expected Outcomes: Router healthy; Router interface errors; Router CPU high
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Clear Router Errors: Clear interface errors and reset counters
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Errors cleared; Errors recurring
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Escalate to Transport: Create ticket for transport team
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Transport team notified
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Enable QoS Protection: Apply QoS policy to protect critical traffic
        - Tools Used: apply_configuration()
        - Expected Outcomes: QoS applied; QoS already active
        - Flow: Proceed to step 7.
        - Note: This step is skippable if not applicable.

    7. Verify Service Impact: Monitor service quality and backhaul status
        - Tools Used: verify_recovery()
        - Expected Outcomes: Backhaul stable; Degradation continues; Transport investigating
        - Flow: Proceed to step end.

    """,
    "ran_bbu_fault_recovery": """
    Workflow: BBU Fault Recovery
    Domain: RAN | Problem Codes: RAN-012 | SLA: 60 minutes
    Description: Baseband Unit hardware/software fault recovery

    1. Verify BBU Alarm: Confirm BBU fault type
        - Tools Used: query_alarm()
        - Expected Outcomes: BBU board fault; BBU software crash; BBU overheating; BBU power fault
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check BBU Health: Query detailed BBU status
        - Tools Used: query_resource_health()
        - Expected Outcomes: Processing board fault; Main control fault; Fan fault; Multiple boards affected
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check BBU Logs: Review BBU system logs for root cause
        - Tools Used: inspect_logs()
        - Expected Outcomes: Software crash identified; Hardware error logged; Temperature alarm logged
        - Flow: Proceed to step 4.

    4. Attempt BBU Reset: Reset BBU or affected board
        - Tools Used: execute_remote_action()
        - Expected Outcomes: BBU recovering; BBU reset failed; Partial recovery
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Verify Cell Recovery: Confirm cells coming back online
        - Tools Used: query_rf_status()
        - Expected Outcomes: All cells recovered; Some cells recovered; Cells still down
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Activate Redundant Board: Switch to redundant BBU board if available
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; No redundancy available
        - Flow: If succeeds, go to step 8; if fails, go to step 7.
        - Note: This step is skippable if not applicable.

    7. Dispatch Field Technician: Create emergency dispatch for BBU repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field dispatch created
        - Flow: Proceed to step 8.

    8. Verify Site Status: Confirm site operational status
        - Tools Used: verify_recovery()
        - Expected Outcomes: Site recovered; Site degraded; Site down - field en route
        - Flow: Proceed to step end.

    """,
    "ran_carrier_aggregation_recovery": """
    Workflow: Carrier Aggregation Failure Recovery
    Domain: RAN | Problem Codes: RAN-017 | SLA: 180 minutes
    Description: CA activation failure troubleshooting

    1. Verify CA Failure: Confirm carrier aggregation not activating
        - Tools Used: query_alarm()
        - Expected Outcomes: CA not activating; SCell addition failure; CA throughput low
        - Flow: If succeeds, go to step 2; if fails, go to step 4.

    2. Check SCell Status: Verify secondary carrier health
        - Tools Used: query_rf_status()
        - Expected Outcomes: SCell healthy; SCell degraded; SCell configuration error
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Review CA Configuration: Verify CA parameters and SCell mapping
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Configuration correct; SCell not mapped; CA threshold issue
        - Flow: If succeeds, go to step 5; if fails, go to step 4.

    4. Apply CA Configuration Fix: Correct CA configuration issues
        - Tools Used: apply_configuration()
        - Expected Outcomes: CA configuration corrected; Configuration change applied
        - Flow: Proceed to step 5.

    5. Verify CA Performance: Monitor CA activation rate
        - Tools Used: verify_recovery()
        - Expected Outcomes: CA functioning; CA improved; CA issue persists
        - Flow: Proceed to step end.

    """,
    "ran_cell_congestion_management": """
    Workflow: Cell Congestion Management
    Domain: RAN | Problem Codes: RAN-005 | SLA: 60 minutes
    Description: High traffic cell congestion mitigation

    1. Verify Congestion Alert: Confirm cell congestion condition
        - Tools Used: query_alarm()
        - Expected Outcomes: PRB utilization high; RRC connection high; User count threshold exceeded
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Analyze Traffic Pattern: Review traffic load and patterns
        - Tools Used: query_performance()
        - Expected Outcomes: Peak hour congestion; Event-driven congestion; Sustained high load
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Carrier Utilization: Assess load distribution across carriers
        - Tools Used: query_resource_health()
        - Expected Outcomes: Load imbalance detected; All carriers loaded; CA capable devices low
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Load Balancing: Enable or adjust inter-frequency load balancing
        - Tools Used: apply_configuration()
        - Expected Outcomes: Load balancing optimized; Limited improvement; Load redistribution active
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Adjust Handover Parameters: Modify HO thresholds to offload traffic
        - Tools Used: apply_configuration()
        - Expected Outcomes: HO parameters adjusted; Neighbor offload increased
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Request Capacity Expansion: Create capacity planning request
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Capacity request submitted
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Enable Cell Barring: Apply selective cell barring if critical
        - Tools Used: apply_configuration()
        - Expected Outcomes: Cell barring applied; Barring not needed
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Verify Congestion Status: Monitor traffic and congestion levels
        - Tools Used: verify_recovery()
        - Expected Outcomes: Congestion relieved; Congestion improved; Congestion ongoing
        - Flow: Proceed to step end.

    """,
    "ran_cell_overshooting_correction": """
    Workflow: Cell Overshooting Correction
    Domain: RAN | Problem Codes: RAN-015 | SLA: 240 minutes
    Description: Cell coverage overshooting mitigation

    1. Verify Overshoot Detection: Confirm cell overshooting condition
        - Tools Used: query_alarm()
        - Expected Outcomes: Overshooting detected via TA; Neighbor anomaly detected; UE distribution abnormal
        - Flow: If succeeds, go to step 2; if fails, go to step 4.

    2. Analyze Coverage Pattern: Review timing advance and UE distribution
        - Tools Used: query_performance()
        - Expected Outcomes: High TA distribution; Abnormal cell selection; Coverage confirmed
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Adjust Tilt/Power: Reduce coverage via tilt or power adjustment
        - Tools Used: apply_configuration()
        - Expected Outcomes: Tilt increased; Power reduced; Configuration applied
        - Flow: If succeeds, go to step 5; if fails, go to step 4.

    4. Request RF Optimization: Schedule drive test and optimization
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Optimization scheduled
        - Flow: Proceed to step 5.

    5. Monitor Coverage Impact: Track coverage changes
        - Tools Used: verify_recovery()
        - Expected Outcomes: Coverage normalized; Improvement observed; Further adjustment needed
        - Flow: Proceed to step end.

    """,
    "ran_cell_site_down_recovery": """
    Workflow: Cell Site Down Recovery
    Domain: RAN | Problem Codes: RAN-001 | SLA: 30 minutes
    Description: Complete cell site outage investigation and recovery

    1. Verify Site Outage: Confirm cell site not responding to network
        - Tools Used: query_alarm()
        - Expected Outcomes: Site unreachable - confirmed; Partial connectivity; Intermittent response
        - Flow: If succeeds, go to step 2; if fails, go to step 11.

    2. Check Backhaul Status: Verify transport link to site
        - Tools Used: test_connectivity()
        - Expected Outcomes: Backhaul up - local issue; Backhaul down; Intermittent backhaul
        - Flow: If succeeds, go to step 3; if fails, go to step 8.

    3. Check Power Status: Verify site power via remote monitoring
        - Tools Used: query_power_system()
        - Expected Outcomes: Power normal; Power fault detected; Unable to query - site offline
        - Flow: If succeeds, go to step 4; if fails, go to step 7.

    4. Attempt Remote Ping: Test IP connectivity to site equipment
        - Tools Used: test_connectivity()
        - Expected Outcomes: eNodeB responding; BBU responding only; No response
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Check eNodeB Status: Query base station operational status
        - Tools Used: query_resource_health()
        - Expected Outcomes: eNodeB fault detected; Software crash; Hardware alarm
        - Flow: If succeeds, go to step 6; if fails, go to step 11.

    6. Attempt eNodeB Reset: Remote reset of base station
        - Tools Used: execute_remote_action()
        - Expected Outcomes: eNodeB recovering; Reset initiated - waiting; Reset failed
        - Flow: If succeeds, go to step 9; if fails, go to step 11.

    7. Initiate Power Recovery: Address power issue via power workflow
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Power recovery in progress; Requires field visit
        - Flow: If succeeds, go to step 9; if fails, go to step 11.

    8. Contact Transport Team: Escalate backhaul issue to transport
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Transport team notified; Cross-functional escalation
        - Flow: Proceed to step 11.

    9. Monitor Site Recovery: Wait for site to come back online
        - Tools Used: query_resource_health()
        - Expected Outcomes: Site online; Site partially recovered; Site still down
        - Flow: If succeeds, go to step 10; if fails, go to step 11.

    10. Verify Cell Sectors: Confirm all sectors operational
        - Tools Used: query_rf_status()
        - Expected Outcomes: All sectors up; Some sectors degraded; Sector failures
        - Flow: If succeeds, go to step 12; if fails, go to step 11.

    11. Dispatch Field Technician: Create emergency dispatch to site
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field dispatch created
        - Flow: Proceed to step 12.

    12. Final Status Verification: Confirm site status and coverage impact
        - Tools Used: verify_recovery()
        - Expected Outcomes: Site fully operational; Site degraded; Site still down - field en route
        - Flow: Proceed to step end.

    """,
    "ran_coverage_complaint_resolution": """
    Workflow: Coverage Complaint Resolution
    Domain: RAN | Problem Codes: SVC-001 | SLA: 240 minutes
    Description: Customer coverage complaint investigation

    1. Review Complaint Details: Analyze customer complaint location and symptoms
        - Tools Used: query_external_factors()
        - Expected Outcomes: Indoor coverage issue; Outdoor weak signal; Specific area affected
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Serving Cell Health: Verify cells serving complaint area
        - Tools Used: query_resource_health()
        - Expected Outcomes: Serving cells healthy; Cell degraded; Coverage gap identified
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Analyze Coverage Data: Review coverage prediction and drive test data
        - Tools Used: query_performance()
        - Expected Outcomes: Coverage adequate per design; Coverage hole confirmed; Terrain obstruction
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Coverage Adjustment: Adjust tilt/power if beneficial
        - Tools Used: apply_configuration()
        - Expected Outcomes: Coverage adjustment applied; Limited improvement possible
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Schedule Site Survey: Request field survey of complaint area
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Site survey scheduled
        - Flow: Proceed to step 6.

    6. Document Resolution: Record findings and actions taken
        - Tools Used: verify_recovery()
        - Expected Outcomes: Issue resolved; Investigation ongoing; Customer notified
        - Flow: Proceed to step end.

    """,
    "ran_device_issue_resolution": """
    Workflow: Subscriber Device Issue Resolution
    Domain: RAN | Problem Codes: SVC-005 | SLA: 120 minutes
    Description: Device compatibility or registration issue

    1. Review Device Issue: Analyze device-related complaint
        - Tools Used: query_external_factors()
        - Expected Outcomes: Registration failure; Device compatibility issue; SIM issue suspected
        - Flow: If succeeds, go to step 2; if fails, go to step 3.

    2. Check Network Registration: Verify device registration status
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Registration successful; Registration rejected; Attach failure
        - Flow: If succeeds, go to step 4; if fails, go to step 3.

    3. Escalate to Core Team: Create ticket for subscriber investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team notified
        - Flow: Proceed to step 4.

    4. Document Resolution: Record device issue findings
        - Tools Used: verify_recovery()
        - Expected Outcomes: Issue resolved; Investigation ongoing; Customer advised
        - Flow: Proceed to step end.

    """,
    "ran_dropped_calls_resolution": """
    Workflow: Dropped Calls Complaint Resolution
    Domain: RAN | Problem Codes: SVC-003 | SLA: 180 minutes
    Description: Customer dropped call complaint investigation

    1. Review Complaint Details: Analyze dropped call complaint
        - Tools Used: query_external_factors()
        - Expected Outcomes: Dropped during mobility; Dropped stationary; Specific location
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check Call Drop KPIs: Review cell drop rate metrics
        - Tools Used: query_performance()
        - Expected Outcomes: Drop rate elevated; Drop rate normal; Specific cause identified
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Analyze Drop Causes: Review RRC release reasons
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Radio link failure; Handover failure; Resource exhaustion
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Serving Cell Health: Verify cell RF health
        - Tools Used: query_rf_status()
        - Expected Outcomes: RF healthy; RF issues detected; Interference present
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Apply Drop Mitigation: Adjust parameters to reduce drops
        - Tools Used: apply_configuration()
        - Expected Outcomes: Mitigation applied; Parameter adjustment made
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Request RF Investigation: Create ticket for RF optimization
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Investigation ticket created
        - Flow: Proceed to step 7.

    7. Document Resolution: Record findings and actions
        - Tools Used: verify_recovery()
        - Expected Outcomes: Issue addressed; Investigation ongoing; Customer notified
        - Flow: Proceed to step end.

    """,
    "ran_gps_sync_recovery": """
    Workflow: GPS Synchronization Recovery
    Domain: RAN | Problem Codes: RAN-010 | SLA: 60 minutes
    Description: GPS timing and synchronization loss recovery

    1. Verify GPS Alarm: Confirm GPS sync loss
        - Tools Used: query_alarm()
        - Expected Outcomes: GPS signal lost; GPS antenna fault; GPS receiver fault; Running on holdover
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check GPS Receiver Status: Query GPS module status and satellite count
        - Tools Used: query_resource_health()
        - Expected Outcomes: No satellites visible; Low satellite count; GPS receiver fault
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Holdover Status: Verify site operating on holdover clock
        - Tools Used: query_resource_health()
        - Expected Outcomes: Holdover active - stable; Holdover degrading; Holdover exceeded
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt GPS Reset: Reset GPS receiver module
        - Tools Used: execute_remote_action()
        - Expected Outcomes: GPS recovering; GPS reacquisition in progress; GPS fault persists
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Enable Backup Sync Source: Switch to alternate timing source if available
        - Tools Used: apply_configuration()
        - Expected Outcomes: Backup sync enabled; No backup available; Sync source switched
        - Flow: Proceed to step 6.

    6. Schedule Field Inspection: Create work order for GPS system inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: GPS inspection scheduled
        - Flow: Proceed to step 7.

    7. Verify Sync Status: Monitor timing and sync recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: GPS recovered; Running on backup sync; Holdover mode - field required
        - Flow: Proceed to step end.

    """,
    "ran_handover_failure_resolution": """
    Workflow: Handover Failure Resolution
    Domain: RAN | Problem Codes: RAN-006 | SLA: 120 minutes
    Description: High handover failure rate troubleshooting

    1. Verify HO Failure Alarm: Confirm high handover failure rate
        - Tools Used: query_alarm()
        - Expected Outcomes: HO failure rate elevated; HO timeout failures; HO preparation failures
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Analyze HO Statistics: Review handover success rates and failure types
        - Tools Used: query_performance()
        - Expected Outcomes: Specific neighbor high failures; All neighbors affected; X2 failures high
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Neighbor Relations: Verify neighbor cell configurations
        - Tools Used: query_topology()
        - Expected Outcomes: Missing neighbor detected; Neighbor config mismatch; Neighbors correct
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Target Cell Health: Verify target cells operational
        - Tools Used: query_resource_health()
        - Expected Outcomes: Target cells healthy; Target cell degraded; Target cell congested
        - Flow: Proceed to step 5.

    5. Adjust HO Parameters: Modify handover thresholds and timers
        - Tools Used: apply_configuration()
        - Expected Outcomes: HO parameters optimized; Parameter adjustment applied; Limited improvement expected
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Check X2 Interface: Verify X2 connectivity between eNodeBs
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: X2 link healthy; X2 congestion; X2 failures detected
        - Flow: Proceed to step 7.

    7. Request RF Optimization: Create work order for drive test optimization
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: RF optimization scheduled
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Monitor HO Success Rate: Track handover performance improvement
        - Tools Used: verify_recovery()
        - Expected Outcomes: HO success rate improved; HO performance stable; Further optimization needed
        - Flow: Proceed to step end.

    """,
    "ran_high_rtwp_resolution": """
    Workflow: High RTWP Resolution
    Domain: RAN | Problem Codes: RAN-004 | SLA: 90 minutes
    Description: Received Total Wideband Power issue resolution

    1. Verify RTWP Alarm: Confirm high RTWP on affected carrier
        - Tools Used: query_alarm()
        - Expected Outcomes: RTWP elevated; RTWP critical; Intermittent RTWP spikes
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check RF Path: Inspect RF path for faults
        - Tools Used: query_rf_status()
        - Expected Outcomes: RF path normal; VSWR alarm; Connector fault suspected
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Analyze Noise Floor: Check for elevated noise floor
        - Tools Used: query_performance()
        - Expected Outcomes: Noise floor elevated; Normal noise floor; External interference indicated
        - Flow: Proceed to step 4.

    4. Attempt RRU Power Adjustment: Adjust receive path gain
        - Tools Used: apply_configuration()
        - Expected Outcomes: RTWP improved; Adjustment limited; No improvement
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Schedule Site Inspection: Create work order for RF path inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Site inspection scheduled
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Enable RTWP Monitoring: Set up enhanced RTWP monitoring
        - Tools Used: apply_configuration()
        - Expected Outcomes: Enhanced monitoring enabled
        - Flow: Proceed to step 7.
        - Note: This step is skippable if not applicable.

    7. Verify RTWP Status: Monitor RTWP trend
        - Tools Used: verify_recovery()
        - Expected Outcomes: RTWP normalized; RTWP improved; RTWP elevated - investigation ongoing
        - Flow: Proceed to step end.

    """,
    "ran_interference_mitigation": """
    Workflow: RF Interference Mitigation
    Domain: RAN | Problem Codes: RAN-003 | SLA: 120 minutes
    Description: Detect and mitigate RF interference

    1. Verify Interference Alarm: Confirm interference detected on sector
        - Tools Used: query_alarm()
        - Expected Outcomes: UL interference confirmed; DL interference suspected; Intermittent interference
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Analyze Interference Pattern: Review interference level and frequency
        - Tools Used: query_rf_status()
        - Expected Outcomes: Constant interference; Periodic interference; Wideband interference
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check Neighbor Cell Status: Verify neighbor cells not causing interference
        - Tools Used: query_resource_health()
        - Expected Outcomes: Neighbors normal; Neighbor misconfigured; Neighbor overshoot detected
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check for External Interference: Assess external interference sources
        - Tools Used: query_external_factors()
        - Expected Outcomes: External source suspected; No external source found; Radar interference detected
        - Flow: Proceed to step 5.

    5. Apply Interference Mitigation: Adjust parameters to reduce interference impact
        - Tools Used: apply_configuration()
        - Expected Outcomes: Mitigation applied; Limited improvement; Interference persists
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Request Spectrum Analysis: Schedule field spectrum analysis
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Spectrum analysis scheduled
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Report to Spectrum Management: File interference report if external source
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Interference report filed
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Verify Interference Status: Monitor interference levels
        - Tools Used: verify_recovery()
        - Expected Outcomes: Interference reduced; Interference stable; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "ran_maintenance_window_execution": """
    Workflow: Maintenance Window Execution
    Domain: RAN | Problem Codes: SVC-004 | SLA: 60 minutes
    Description: Planned maintenance window monitoring

    1. Verify Maintenance Start: Confirm maintenance window active
        - Tools Used: query_external_factors()
        - Expected Outcomes: Maintenance window active; Window scheduled; Window completed
        - Flow: If succeeds, go to step 2; if fails, go to step 3.

    2. Monitor Service Impact: Track service during maintenance
        - Tools Used: query_resource_health()
        - Expected Outcomes: Impact within expected; Impact higher than expected; No impact
        - Flow: Proceed to step 3.

    3. Verify Post-Maintenance: Confirm service restored post-maintenance
        - Tools Used: verify_recovery()
        - Expected Outcomes: Service restored; Partial restoration; Issues detected
        - Flow: Proceed to step end.

    """,
    "ran_massive_mimo_recovery": """
    Workflow: Massive MIMO Fault Recovery
    Domain: RAN | Problem Codes: RAN-020 | SLA: 120 minutes
    Description: Massive MIMO antenna array fault recovery

    1. Verify MIMO Alarm: Confirm massive MIMO fault
        - Tools Used: query_alarm()
        - Expected Outcomes: Antenna element fault; Beamforming degraded; TRX chain failure
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Antenna Status: Query antenna array health
        - Tools Used: query_rf_status()
        - Expected Outcomes: Multiple elements failed; Single element fault; Calibration error
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Attempt Array Recalibration: Trigger antenna array recalibration
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Recalibration successful; Recalibration failed; Hardware fault persists
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Verify Beamforming: Check beamforming functionality restored
        - Tools Used: query_performance()
        - Expected Outcomes: Beamforming restored; Degraded operation; Beamforming disabled
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Schedule Field Service: Create work order for MIMO repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field service scheduled
        - Flow: Proceed to step 6.

    6. Verify Capacity Impact: Monitor capacity and throughput
        - Tools Used: verify_recovery()
        - Expected Outcomes: MIMO recovered; Operating in degraded mode; Field repair required
        - Flow: Proceed to step end.

    """,
    "ran_parameter_correction": """
    Workflow: Parameter Misconfiguration Correction
    Domain: RAN | Problem Codes: RAN-013 | SLA: 120 minutes
    Description: Cell parameter misconfiguration identification and correction

    1. Verify Configuration Alert: Confirm parameter misconfiguration detected
        - Tools Used: query_alarm()
        - Expected Outcomes: Parameter audit mismatch; KPI degradation detected; Configuration drift
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Run Configuration Audit: Compare current config against baseline
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Deviations identified; Multiple parameters affected; Minor drift only
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Assess Impact: Determine performance impact of misconfiguration
        - Tools Used: query_performance()
        - Expected Outcomes: Significant KPI impact; Minor impact; No measurable impact
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Corrective Configuration: Restore parameters to baseline
        - Tools Used: apply_configuration()
        - Expected Outcomes: Parameters corrected; Partial correction; Correction requires review
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Escalate to Engineering: Request engineering review of configuration
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Engineering review requested
        - Flow: Proceed to step 6.

    6. Verify Performance: Monitor KPI improvement
        - Tools Used: verify_recovery()
        - Expected Outcomes: KPIs improved; KPIs stable; Continued monitoring needed
        - Flow: Proceed to step end.

    """,
    "ran_pim_interference_resolution": """
    Workflow: PIM Interference Resolution
    Domain: RAN | Problem Codes: RAN-016 | SLA: 180 minutes
    Description: Passive Intermodulation interference mitigation

    1. Verify PIM Detection: Confirm PIM interference suspected
        - Tools Used: query_alarm()
        - Expected Outcomes: PIM pattern detected; Interference correlated with TX; RTWP pattern suspicious
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Analyze Interference Pattern: Correlate interference with TX power
        - Tools Used: query_rf_status()
        - Expected Outcomes: PIM confirmed - TX correlated; Pattern inconclusive; External interference
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Recent Work History: Review recent antenna work on site
        - Tools Used: query_external_factors()
        - Expected Outcomes: Recent work performed; No recent changes
        - Flow: Proceed to step 4.
        - Note: This step is skippable if not applicable.

    4. Temporary TX Power Reduction: Reduce TX power to confirm PIM reduction
        - Tools Used: apply_configuration()
        - Expected Outcomes: PIM reduced with lower power; No change observed
        - Flow: Proceed to step 5.

    5. Schedule PIM Hunt: Create work order for PIM source identification
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: PIM hunt scheduled
        - Flow: Proceed to step 6.

    6. Verify Mitigation Status: Monitor interference levels
        - Tools Used: verify_recovery()
        - Expected Outcomes: PIM mitigated; Operating at reduced power; Field investigation required
        - Flow: Proceed to step end.

    """,
    "ran_prb_availability_resolution": """
    Workflow: Low PRB Availability Resolution
    Domain: RAN | Problem Codes: RAN-018 | SLA: 60 minutes
    Description: Physical Resource Block shortage mitigation

    1. Verify PRB Alert: Confirm low PRB availability
        - Tools Used: query_alarm()
        - Expected Outcomes: PRB utilization critical; PRB shortage detected; DL/UL imbalance
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Analyze PRB Usage: Review PRB utilization by traffic type
        - Tools Used: query_performance()
        - Expected Outcomes: High VoLTE load; Data traffic heavy; Control channel heavy
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Apply PRB Optimization: Adjust PRB allocation and scheduling
        - Tools Used: apply_configuration()
        - Expected Outcomes: Scheduling optimized; PRB allocation adjusted
        - Flow: If succeeds, go to step 6; if fails, go to step 4.

    4. Enable Load Balancing: Activate inter-frequency load balancing
        - Tools Used: apply_configuration()
        - Expected Outcomes: Load balancing active; Traffic offloaded
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Request Capacity Addition: Submit capacity expansion request
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Capacity request submitted
        - Flow: Proceed to step 6.

    6. Verify PRB Status: Monitor PRB availability improvement
        - Tools Used: verify_recovery()
        - Expected Outcomes: PRB availability improved; PRB stable; Capacity addition required
        - Flow: Proceed to step end.

    """,
    "ran_rru_communication_recovery": """
    Workflow: RRU Communication Recovery
    Domain: RAN | Problem Codes: RAN-008 | SLA: 60 minutes
    Description: Remote Radio Unit communication failure recovery

    1. Verify RRU Alarm: Confirm RRU communication loss
        - Tools Used: query_alarm()
        - Expected Outcomes: RRU link down; RRU timeout; Multiple RRUs affected
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check CPRI/Fiber Link: Verify CPRI or eCPRI link status
        - Tools Used: test_connectivity()
        - Expected Outcomes: CPRI link down; CPRI errors high; Fiber fault indicated
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check BBU Status: Verify BBU board health
        - Tools Used: query_resource_health()
        - Expected Outcomes: BBU healthy; BBU interface fault; BBU software error
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt RRU Reset: Remote reset of RRU
        - Tools Used: execute_remote_action()
        - Expected Outcomes: RRU recovering; RRU not responding; Reset command failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Reset BBU Interface: Reset BBU CPRI interface board
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Interface recovered; Interface fault persists
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Check RRU Power: Verify RRU has power
        - Tools Used: query_power_system()
        - Expected Outcomes: RRU power OK; RRU power fault; Cannot verify remotely
        - Flow: Proceed to step 7.

    7. Dispatch Field Technician: Create dispatch for RRU repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field dispatch created
        - Flow: Proceed to step 8.

    8. Verify Sector Status: Confirm affected sectors operational status
        - Tools Used: verify_recovery()
        - Expected Outcomes: RRU recovered; Sector down - field en route; Partial recovery
        - Flow: Proceed to step end.

    """,
    "ran_sector_outage_recovery": """
    Workflow: Sector Outage Recovery
    Domain: RAN | Problem Codes: RAN-002 | SLA: 60 minutes
    Description: Individual cell sector failure recovery

    1. Verify Sector Alarm: Confirm sector outage and identify affected sector
        - Tools Used: query_alarm()
        - Expected Outcomes: Sector alpha down; Sector beta down; Sector gamma down; Multiple sectors
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check RF Chain Status: Query RF module and antenna status
        - Tools Used: query_rf_status()
        - Expected Outcomes: PA fault detected; Antenna VSWR alarm; RF path normal; RRU fault
        - Flow: If succeeds, go to step 3; if fails, go to step 7.

    3. Check RRU Status: Query remote radio unit health
        - Tools Used: query_resource_health()
        - Expected Outcomes: RRU online; RRU fault; RRU communication lost
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt Sector Reset: Reset RF path for affected sector
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Sector recovering; Reset failed; Hardware fault persists
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Attempt RRU Reset: Power cycle remote radio unit
        - Tools Used: execute_remote_action()
        - Expected Outcomes: RRU recovering; RRU failed to restart; Hardware replacement needed
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Verify Sector Recovery: Confirm sector back on air
        - Tools Used: query_rf_status()
        - Expected Outcomes: Sector transmitting; Reduced power; Sector still down
        - Flow: If succeeds, go to step 9; if fails, go to step 7.

    7. Enable Capacity Compensation: Adjust neighboring sectors to compensate
        - Tools Used: apply_configuration()
        - Expected Outcomes: Neighbor compensation applied; Limited compensation possible
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Schedule Field Repair: Create work order for hardware repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field repair scheduled
        - Flow: Proceed to step 9.

    9. Verify Coverage Impact: Assess coverage gap and customer impact
        - Tools Used: verify_recovery()
        - Expected Outcomes: Sector recovered; Coverage compensated; Coverage gap exists
        - Flow: Proceed to step end.

    """,
    "ran_software_upgrade_recovery": """
    Workflow: Software Upgrade Failure Recovery
    Domain: RAN | Problem Codes: RAN-014 | SLA: 60 minutes
    Description: Failed software upgrade rollback and recovery

    1. Verify Upgrade Failure: Confirm software upgrade failed
        - Tools Used: query_alarm()
        - Expected Outcomes: Upgrade failed mid-process; Version mismatch; Boot failure post-upgrade
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check System Status: Query node operational state
        - Tools Used: query_resource_health()
        - Expected Outcomes: System partially operational; System in degraded state; System down
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Review Upgrade Logs: Analyze upgrade failure logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: Database migration failed; File system error; Memory exhaustion
        - Flow: Proceed to step 4.

    4. Initiate Rollback: Roll back to previous software version
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Rollback successful; Rollback in progress; Rollback failed
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Attempt Emergency Boot: Boot from recovery image
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Recovery boot successful; Recovery failed
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Verify System Recovery: Confirm system operational post-rollback
        - Tools Used: query_resource_health()
        - Expected Outcomes: System recovered; System degraded; Issues persist
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Dispatch Field Support: Create emergency dispatch for manual recovery
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field dispatch created
        - Flow: Proceed to step 8.

    8. Document and Report: Record failure for vendor escalation
        - Tools Used: verify_recovery()
        - Expected Outcomes: System recovered - incident documented; Recovery ongoing; Vendor escalation needed
        - Flow: Proceed to step end.

    """,
    "ran_speed_complaint_resolution": """
    Workflow: Speed Complaint Resolution
    Domain: RAN | Problem Codes: SVC-002 | SLA: 240 minutes
    Description: Customer throughput complaint investigation

    1. Review Complaint Details: Analyze customer speed complaint
        - Tools Used: query_external_factors()
        - Expected Outcomes: Low speed reported; Intermittent speed issues; Specific times affected
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Cell Performance: Review cell throughput and utilization
        - Tools Used: query_performance()
        - Expected Outcomes: Cell throughput normal; Cell congested; Backhaul limited
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Device Capability: Verify device supports available features
        - Tools Used: query_resource_health()
        - Expected Outcomes: Device CA capable; Device limited; Device category low
        - Flow: Proceed to step 4.
        - Note: This step is skippable if not applicable.

    4. Apply Throughput Optimization: Adjust parameters for throughput
        - Tools Used: apply_configuration()
        - Expected Outcomes: Optimization applied; Limited improvement expected
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Request Detailed Analysis: Create ticket for performance analysis
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Analysis ticket created
        - Flow: Proceed to step 6.

    6. Document Resolution: Record findings and recommendations
        - Tools Used: verify_recovery()
        - Expected Outcomes: Issue addressed; Investigation ongoing; Customer notified
        - Flow: Proceed to step end.

    """,
    "ran_voice_quality_resolution": """
    Workflow: Voice Quality Degradation Resolution
    Domain: RAN | Problem Codes: RAN-019 | SLA: 90 minutes
    Description: VoLTE/VoNR quality issue troubleshooting

    1. Verify Voice Quality Alert: Confirm voice quality degradation
        - Tools Used: query_alarm()
        - Expected Outcomes: MOS score degraded; Call drop rate elevated; Voice jitter detected
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Analyze Voice KPIs: Review VoLTE performance metrics
        - Tools Used: query_performance()
        - Expected Outcomes: DL bearer quality low; UL bearer quality low; SRVCC failures high
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Check QCI 1 Bearer: Verify voice bearer configuration
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Bearer configuration OK; QCI 1 issues detected; GBR allocation problem
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Verify IMS Connectivity: Check IMS platform connectivity
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: IMS connectivity OK; IMS latency elevated; SIP failures detected
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Apply Voice Optimization: Adjust VoLTE parameters
        - Tools Used: apply_configuration()
        - Expected Outcomes: Voice parameters optimized; Configuration applied
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to Voice Team: Create ticket for voice engineering
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Voice team notified
        - Flow: Proceed to step 7.

    7. Verify Voice Quality: Monitor voice KPI improvement
        - Tools Used: verify_recovery()
        - Expected Outcomes: Voice quality improved; Voice quality stable; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "ran_vswr_alarm_resolution": """
    Workflow: VSWR Alarm Resolution
    Domain: RAN | Problem Codes: RAN-007 | SLA: 90 minutes
    Description: Voltage Standing Wave Ratio fault resolution

    1. Verify VSWR Alarm: Confirm VSWR threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: VSWR warning; VSWR critical; VSWR intermittent
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check RF Path Status: Get detailed RF path measurements
        - Tools Used: query_rf_status()
        - Expected Outcomes: VSWR elevated on antenna; VSWR elevated on feeder; VSWR on jumper
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Check Recent Work History: Verify recent site work that may have caused issue
        - Tools Used: query_external_factors()
        - Expected Outcomes: Recent antenna work performed; Recent weather event; No recent changes
        - Flow: Proceed to step 4.
        - Note: This step is skippable if not applicable.

    4. Reduce TX Power: Lower transmit power to protect equipment
        - Tools Used: apply_configuration()
        - Expected Outcomes: TX power reduced; Power already at minimum; PA protection activated
        - Flow: Proceed to step 5.

    5. Schedule Field Inspection: Create work order for antenna system inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Antenna inspection scheduled
        - Flow: Proceed to step 6.

    6. Verify Sector Impact: Assess coverage and capacity impact
        - Tools Used: verify_recovery()
        - Expected Outcomes: Sector operational at reduced power; Sector significantly degraded; Field repair required
        - Flow: Proceed to step end.

    """,
    "signaling_delay_resolution": """
    Workflow: Signaling Delay Resolution
    Domain: SIGNALING | Problem Codes: SIG-009 | SLA: 60 minutes
    Description: Signaling path latency troubleshooting

    1. Verify Delay Alarm: Confirm signaling delay threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: Response time high; Timeout rate elevated; Procedure delay
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Measure Signaling Latency: Test signaling path delay
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: High latency confirmed; Variable latency; Network path delay
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Processing Load: Verify node processing capacity
        - Tools Used: query_resource_health()
        - Expected Outcomes: Processing OK; CPU high; Queue delay
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Optimize Signaling Path: Adjust routing or parameters to reduce delay
        - Tools Used: apply_configuration()
        - Expected Outcomes: Path optimized; Timer adjusted; Limited improvement
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Request Network Review: Create ticket for transport path analysis
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Network review scheduled
        - Flow: Proceed to step 6.

    6. Verify Delay Status: Monitor signaling latency
        - Tools Used: verify_recovery()
        - Expected Outcomes: Latency improved; Latency stable; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "signaling_diameter_recovery": """
    Workflow: Diameter Peer Recovery
    Domain: SIGNALING | Problem Codes: SIG-002 | SLA: 15 minutes
    Description: Diameter signaling peer failure recovery

    1. Verify Diameter Alarm: Confirm Diameter peer connection lost
        - Tools Used: query_alarm()
        - Expected Outcomes: Diameter peer down; DWR timeout; Transport failure
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Diameter Stack: Verify Diameter agent status
        - Tools Used: query_resource_health()
        - Expected Outcomes: Local stack healthy; Stack overloaded; Stack fault
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Test Peer Connectivity: Verify IP connectivity to Diameter peer
        - Tools Used: test_connectivity()
        - Expected Outcomes: Peer reachable; Peer unreachable; Port blocked
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt Diameter Reconnect: Force reconnection to Diameter peer
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Peer reconnecting; CER/CEA exchange started; Reconnect failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Failover to Backup Peer: Route to secondary Diameter peer
        - Tools Used: apply_configuration()
        - Expected Outcomes: Failover successful; No backup peer; Backup congested
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Escalate to DRA Team: Create ticket for DRA/Diameter investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: DRA team notified
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Implement Traffic Throttling: Apply overload control if needed
        - Tools Used: apply_configuration()
        - Expected Outcomes: Throttling enabled; OLC applied
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Verify Diameter Status: Monitor Diameter peer recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Peer restored; Running on backup; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "signaling_gtp_tunnel_recovery": """
    Workflow: GTP Tunnel Failure Recovery
    Domain: SIGNALING | Problem Codes: SIG-004 | SLA: 15 minutes
    Description: GTP-C/GTP-U tunnel failure recovery

    1. Verify GTP Alarm: Confirm GTP tunnel failure
        - Tools Used: query_alarm()
        - Expected Outcomes: GTP-C path failure; GTP-U echo timeout; Tunnel deletion high
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check S/P-GW Status: Verify gateway operational status
        - Tools Used: query_resource_health()
        - Expected Outcomes: Gateway healthy; Gateway overloaded; Gateway fault
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Test GTP Path: Verify GTP connectivity
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Path healthy; Echo loss; Path congested
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Attempt Path Recovery: Clear and rebuild GTP path
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Path recovering; Path established; Recovery failed
        - Flow: If succeeds, go to step 8; if fails, go to step 5.

    5. Failover to Backup Gateway: Redirect to secondary S/P-GW
        - Tools Used: apply_configuration()
        - Expected Outcomes: Failover initiated; No backup available
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Escalate to Core Team: Create critical ticket for EPC/5GC investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team engaged
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Enable GTP Optimization: Apply GTP overload controls
        - Tools Used: apply_configuration()
        - Expected Outcomes: Controls applied; Already optimized
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Verify GTP Status: Monitor GTP tunnel recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: GTP recovered; Running on backup; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "signaling_overload_mitigation": """
    Workflow: Signaling Overload Mitigation
    Domain: SIGNALING | Problem Codes: SIG-008 | SLA: 30 minutes
    Description: Signaling plane overload detection and mitigation

    1. Verify Overload Alarm: Confirm signaling overload condition
        - Tools Used: query_alarm()
        - Expected Outcomes: Message rate high; Queue building; Reject rate elevated
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Identify Overload Source: Determine cause of signaling overload
        - Tools Used: query_performance()
        - Expected Outcomes: Attach storm; Paging flood; Normal peak traffic
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Node Capacity: Verify signaling node capacity
        - Tools Used: query_resource_health()
        - Expected Outcomes: At capacity; Undersized; Unusual load pattern
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Enable Overload Controls: Activate signaling overload mechanisms
        - Tools Used: apply_configuration()
        - Expected Outcomes: OLC enabled; Rate limiting active; Selective rejection
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Request Load Shedding: Implement traffic management
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Load shedding active; Traffic shaped
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate Capacity Issue: Create ticket for capacity review
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Capacity team notified
        - Flow: Proceed to step 7.

    7. Verify Load Status: Monitor signaling load levels
        - Tools Used: verify_recovery()
        - Expected Outcomes: Load normalized; Load stabilized; OLC active
        - Flow: Proceed to step end.

    """,
    "signaling_routing_failure_recovery": """
    Workflow: Message Routing Failure Recovery
    Domain: SIGNALING | Problem Codes: SIG-010 | SLA: 30 minutes
    Description: Signaling message routing failure troubleshooting

    1. Verify Routing Alarm: Confirm message routing failure
        - Tools Used: query_alarm()
        - Expected Outcomes: Route not found; Destination unreachable; Routing loop detected
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Routing Tables: Verify signaling routing configuration
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Missing route; Incorrect route; Routes OK - destination down
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Destination Status: Verify target node reachability
        - Tools Used: query_resource_health()
        - Expected Outcomes: Destination reachable; Destination down; Destination overloaded
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Route Correction: Fix routing configuration
        - Tools Used: apply_configuration()
        - Expected Outcomes: Route added; Route corrected; Alternate route configured
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Escalate Routing Issue: Create ticket for routing investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Routing issue escalated
        - Flow: Proceed to step 6.

    6. Verify Routing Status: Monitor message routing success
        - Tools Used: verify_recovery()
        - Expected Outcomes: Routing restored; Alternate route active; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "signaling_s1_n2_recovery": """
    Workflow: S1/N2 Interface Recovery
    Domain: SIGNALING | Problem Codes: SIG-001 | SLA: 15 minutes
    Description: S1-MME or N2 interface failure recovery

    1. Verify S1/N2 Alarm: Confirm S1-MME or N2 interface down
        - Tools Used: query_alarm()
        - Expected Outcomes: S1-MME link down; N2 interface down; SCTP association lost
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Check SCTP Status: Verify SCTP association state
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: SCTP down; SCTP heartbeat timeout; SCTP path failed
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Test IP Connectivity to Core: Verify IP path to MME/AMF
        - Tools Used: test_connectivity()
        - Expected Outcomes: Path OK; Path down; High latency/loss
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Check Core Node Status: Verify MME/AMF operational status
        - Tools Used: query_resource_health()
        - Expected Outcomes: Core node healthy; Core node overloaded; Core node down
        - Flow: If succeeds, go to step 5; if fails, go to step 7.

    5. Attempt SCTP Reset: Reset SCTP association on eNodeB/gNodeB
        - Tools Used: execute_remote_action()
        - Expected Outcomes: SCTP recovering; Reset failed; Association reestablishing
        - Flow: If succeeds, go to step 9; if fails, go to step 6.

    6. Switch to Backup MME/AMF: Redirect to secondary core node
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; No backup available; Backup also affected
        - Flow: If succeeds, go to step 9; if fails, go to step 7.

    7. Escalate to Core Team: Create critical ticket for core investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team engaged
        - Flow: If succeeds, go to step 8; if fails, go to step 9.

    8. Enable S1 Flex Rerouting: Configure S1-flex to alternate pool
        - Tools Used: apply_configuration()
        - Expected Outcomes: Rerouting enabled; Flex not available
        - Flow: Proceed to step 9.
        - Note: This step is skippable if not applicable.

    9. Verify S1/N2 Status: Monitor interface recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: S1/N2 restored; Running on backup; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "signaling_s1ap_procedure_recovery": """
    Workflow: S1-AP Procedure Failure Recovery
    Domain: SIGNALING | Problem Codes: SIG-005 | SLA: 30 minutes
    Description: S1-AP signaling procedure failure troubleshooting

    1. Verify S1-AP Alarm: Confirm S1-AP procedure failures
        - Tools Used: query_alarm()
        - Expected Outcomes: Setup failures elevated; Reset procedure triggered; UE context failures
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Analyze S1-AP Statistics: Review S1-AP procedure success rates
        - Tools Used: query_performance()
        - Expected Outcomes: Attach failures; Handover failures; Paging failures
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check MME Load: Verify MME capacity and load
        - Tools Used: query_resource_health()
        - Expected Outcomes: MME healthy; MME overloaded; MME rejecting
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Review S1-AP Configuration: Verify S1-AP parameters
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Config OK; Timer mismatch; Capacity exceeded
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Apply S1-AP Tuning: Adjust S1-AP parameters
        - Tools Used: apply_configuration()
        - Expected Outcomes: Parameters adjusted; Tuning applied
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to Core Team: Create ticket for MME investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Core team notified
        - Flow: Proceed to step 7.

    7. Verify S1-AP Performance: Monitor S1-AP procedure success rate
        - Tools Used: verify_recovery()
        - Expected Outcomes: S1-AP improved; Performance stable; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "signaling_sctp_recovery": """
    Workflow: SCTP Association Recovery
    Domain: SIGNALING | Problem Codes: SIG-006 | SLA: 15 minutes
    Description: SCTP association failure recovery

    1. Verify SCTP Alarm: Confirm SCTP association lost
        - Tools Used: query_alarm()
        - Expected Outcomes: Association down; Path failure; Heartbeat timeout
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check SCTP Path Status: Verify SCTP multihoming paths
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Primary path down; Both paths down; Path flapping
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Test SCTP Connectivity: Verify IP connectivity for SCTP paths
        - Tools Used: test_connectivity()
        - Expected Outcomes: Primary path OK; Secondary path OK; Both paths unreachable
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Force SCTP Failover: Switch to alternate SCTP path
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Failover successful; Secondary path active
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Reset SCTP Association: Restart SCTP association
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Association reestablishing; Reset failed
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate Path Issue: Create ticket for network/transport investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Transport team engaged
        - Flow: Proceed to step 7.

    7. Verify SCTP Status: Monitor SCTP association recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Association restored; Running on backup path; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "signaling_sigtran_recovery": """
    Workflow: SIGTRAN Link Failure Recovery
    Domain: SIGNALING | Problem Codes: SIG-007 | SLA: 15 minutes
    Description: SIGTRAN/SS7 over IP link recovery

    1. Verify SIGTRAN Alarm: Confirm SIGTRAN link failure
        - Tools Used: query_alarm()
        - Expected Outcomes: M3UA link down; M2PA failure; SG unreachable
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check SG Status: Verify Signaling Gateway status
        - Tools Used: query_resource_health()
        - Expected Outcomes: SG healthy; SG overloaded; SG unreachable
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Test SIGTRAN Path: Verify SIGTRAN connectivity
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Path healthy; Path blocked; SCTP layer issue
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Activate Backup Linkset: Switch to redundant SIGTRAN linkset
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Backup linkset active; No backup available
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Reset SIGTRAN Link: Restart failed SIGTRAN link
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Link recovering; Link activation in progress; Reset failed
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to SS7 Team: Create critical ticket for SS7/SIGTRAN investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: SS7 team engaged
        - Flow: Proceed to step 7.

    7. Verify SIGTRAN Status: Monitor SIGTRAN link recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Link restored; Running on backup; Recovery ongoing
        - Flow: Proceed to step end.

    """,
    "signaling_sip_registration_recovery": """
    Workflow: SIP Registration Failure Recovery
    Domain: SIGNALING | Problem Codes: SIG-003 | SLA: 30 minutes
    Description: VoLTE/VoNR SIP registration failure troubleshooting

    1. Verify SIP Alarm: Confirm SIP registration failure rate elevated
        - Tools Used: query_alarm()
        - Expected Outcomes: Registration failures high; 401 responses elevated; Timeout failures
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check P-CSCF Status: Verify P-CSCF operational status
        - Tools Used: query_resource_health()
        - Expected Outcomes: P-CSCF healthy; P-CSCF overloaded; P-CSCF unreachable
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Verify IMS Path: Test SIP signaling path to IMS
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: Path healthy; Path congested; Path blocked
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check HSS Connectivity: Verify HSS/UDM reachability for auth
        - Tools Used: verify_signaling_path()
        - Expected Outcomes: HSS reachable; HSS overloaded; Auth failures
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Adjust SIP Routing: Route to alternate P-CSCF pool
        - Tools Used: apply_configuration()
        - Expected Outcomes: Routing adjusted; Pool switched
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Escalate to IMS Team: Create ticket for IMS investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: IMS team notified
        - Flow: Proceed to step 7.

    7. Verify Registration Rate: Monitor SIP registration success rate
        - Tools Used: verify_recovery()
        - Expected Outcomes: Registration rate recovered; Rate improving; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "transport_fiber_cut_response": """
    Workflow: Fiber Cut Response
    Domain: TRANSPORT | Problem Codes: TRN-001 | SLA: 30 minutes
    Description: Fiber optic cable cut detection and response

    1. Verify Fiber Alarm: Confirm fiber cut or loss of light
        - Tools Used: query_alarm()
        - Expected Outcomes: Loss of light confirmed; High optical attenuation; Multiple fibers affected
        - Flow: If succeeds, go to step 2; if fails, go to step 8.

    2. Identify Affected Services: Determine services impacted by fiber cut
        - Tools Used: query_topology()
        - Expected Outcomes: Cell sites affected; Core links affected; Customer circuits affected
        - Flow: If succeeds, go to step 3; if fails, go to step 7.

    3. Check OTDR Data: Review optical time domain reflectometer data
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Cut location identified; OTDR data inconclusive; Multiple faults detected
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Activate Protection Path: Switch to protection fiber if available
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Protection active; No protection available; Protection also affected
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Implement Rerouting: Reroute traffic via alternate paths
        - Tools Used: apply_configuration()
        - Expected Outcomes: Traffic rerouted; Partial restoration; No alternate path
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Verify Service Restoration: Confirm services recovered via protection/reroute
        - Tools Used: test_connectivity()
        - Expected Outcomes: Services restored; Partial restoration; Services impacted
        - Flow: Proceed to step 7.

    7. Dispatch Fiber Repair Team: Create emergency dispatch for fiber repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Fiber repair dispatch created
        - Flow: If succeeds, go to step 8; if fails, go to step 9.

    8. Notify Affected Customers: Send outage notifications if applicable
        - Tools Used: query_external_factors()
        - Expected Outcomes: Notifications sent; No customer impact
        - Flow: Proceed to step 9.
        - Note: This step is skippable if not applicable.

    9. Monitor Recovery Status: Track fiber repair progress
        - Tools Used: verify_recovery()
        - Expected Outcomes: Protected - repair in progress; Degraded - repair in progress; Full outage - repair underway
        - Flow: Proceed to step end.

    """,
    "transport_high_latency_resolution": """
    Workflow: High Latency Resolution
    Domain: TRANSPORT | Problem Codes: TRN-005 | SLA: 90 minutes
    Description: Transport path latency troubleshooting

    1. Verify Latency Alarm: Confirm latency threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: Latency elevated; Latency spikes detected; Consistent high latency
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Test Path Latency: Measure end-to-end latency
        - Tools Used: test_connectivity()
        - Expected Outcomes: Latency Xms confirmed; Variable latency; Timeout detected
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Identify High Latency Hop: Locate source of latency
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Specific hop identified; Distributed latency; Routing inefficient
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Optimize Routing: Adjust routing to reduce latency
        - Tools Used: apply_configuration()
        - Expected Outcomes: Route optimized; Limited improvement; Best path already used
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Request Capacity Review: Create ticket for capacity analysis
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Capacity review scheduled
        - Flow: Proceed to step 6.

    6. Verify Latency Status: Monitor latency improvement
        - Tools Used: verify_recovery()
        - Expected Outcomes: Latency normalized; Latency improved; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "transport_interface_errors_resolution": """
    Workflow: Interface Errors Resolution
    Domain: TRANSPORT | Problem Codes: TRN-007 | SLA: 90 minutes
    Description: Network interface error troubleshooting

    1. Verify Interface Alarm: Confirm interface error threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: CRC errors elevated; Input errors high; Carrier transitions
        - Flow: If succeeds, go to step 2; if fails, go to step 5.

    2. Check Interface Counters: Get detailed interface error statistics
        - Tools Used: query_resource_health()
        - Expected Outcomes: Layer 1 errors; Layer 2 errors; Duplex mismatch suspected
        - Flow: If succeeds, go to step 3; if fails, go to step 4.

    3. Check Physical Layer: Verify optics and cable integrity
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Optical levels OK; RX power low; TX power fault
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Clear Counters and Monitor: Reset counters and watch for new errors
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Errors continuing; Errors stopped; Intermittent errors
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Schedule Physical Repair: Create ticket for cable/optic replacement
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Field repair scheduled
        - Flow: Proceed to step 6.

    6. Verify Interface Status: Monitor interface error rate
        - Tools Used: verify_recovery()
        - Expected Outcomes: Errors resolved; Errors reduced; Repair required
        - Flow: Proceed to step end.

    """,
    "transport_microwave_degradation_response": """
    Workflow: Microwave Link Degradation Response
    Domain: TRANSPORT | Problem Codes: TRN-002 | SLA: 60 minutes
    Description: Microwave link performance degradation troubleshooting

    1. Verify Microwave Alarm: Confirm microwave link degradation
        - Tools Used: query_alarm()
        - Expected Outcomes: Signal fade detected; BER elevated; Modulation downshift; Link down
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Weather Conditions: Verify weather impact on link
        - Tools Used: query_external_factors()
        - Expected Outcomes: Rain fade likely; No weather issues; High humidity detected
        - Flow: Proceed to step 3.

    3. Check Link Status: Query microwave terminal status
        - Tools Used: query_resource_health()
        - Expected Outcomes: RSL degraded; Equipment fault; Antenna misalignment suspected
        - Flow: If succeeds, go to step 4; if fails, go to step 6.

    4. Enable ACM Optimization: Verify adaptive coding and modulation active
        - Tools Used: apply_configuration()
        - Expected Outcomes: ACM optimized; Already at lowest modulation; Configuration applied
        - Flow: Proceed to step 5.

    5. Activate Link Protection: Enable backup link if available
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Protection active; No protection available; 1+1 already active
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Schedule Site Visit: Create work order for antenna inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Site inspection scheduled
        - Flow: If succeeds, go to step 7; if fails, go to step 8.

    7. Apply QoS Policy: Prioritize critical traffic during degradation
        - Tools Used: apply_configuration()
        - Expected Outcomes: QoS applied; QoS already active
        - Flow: Proceed to step 8.
        - Note: This step is skippable if not applicable.

    8. Monitor Link Status: Track link recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Link recovering; Link stable at lower rate; Link still degraded
        - Flow: Proceed to step end.

    """,
    "transport_mpls_lsp_recovery": """
    Workflow: MPLS LSP Failure Recovery
    Domain: TRANSPORT | Problem Codes: TRN-003 | SLA: 30 minutes
    Description: MPLS Label Switched Path failure recovery

    1. Verify LSP Alarm: Confirm MPLS LSP down
        - Tools Used: query_alarm()
        - Expected Outcomes: Primary LSP down; Backup LSP active; Multiple LSPs affected
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check LSP Path: Trace LSP path and identify failure point
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Failure node identified; Failure link identified; Path unreachable
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Check Router Status: Query router at failure point
        - Tools Used: query_resource_health()
        - Expected Outcomes: Router healthy - link issue; Router interface down; Router unreachable
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Force LSP Recomputation: Trigger RSVP path recomputation
        - Tools Used: execute_remote_action()
        - Expected Outcomes: LSP rerouted; No alternate path found; Recomputation in progress
        - Flow: If succeeds, go to step 6; if fails, go to step 5.

    5. Check Physical Layer: Verify underlying connectivity
        - Tools Used: test_connectivity()
        - Expected Outcomes: Physical link down; Physical layer OK; Errors detected
        - Flow: If succeeds, go to step 6; if fails, go to step 7.

    6. Verify Service Impact: Check services using affected LSP
        - Tools Used: query_topology()
        - Expected Outcomes: Services rerouted; Services degraded; Services impacted
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to Transport Core: Create high priority ticket for MPLS repair
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Transport core notified
        - Flow: Proceed to step 8.

    8. Monitor LSP Status: Track LSP recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: Primary LSP restored; Running on backup; Recovery in progress
        - Flow: Proceed to step end.

    """,
    "transport_packet_loss_resolution": """
    Workflow: High Packet Loss Resolution
    Domain: TRANSPORT | Problem Codes: TRN-004 | SLA: 60 minutes
    Description: Transport path packet loss troubleshooting

    1. Verify Packet Loss Alarm: Confirm packet loss threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: Packet loss elevated; Intermittent loss; Severe packet loss
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Test Path Connectivity: Run path quality tests
        - Tools Used: test_connectivity()
        - Expected Outcomes: Loss confirmed at X%; Intermittent loss detected; Path test passed
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Identify Loss Point: Locate where packet loss is occurring
        - Tools Used: run_diagnostics()
        - Expected Outcomes: Loss at specific hop; Loss distributed; Last mile issue
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Interface Counters: Review router interface error counters
        - Tools Used: query_resource_health()
        - Expected Outcomes: Input errors high; Output drops high; CRC errors; Counters normal
        - Flow: Proceed to step 5.

    5. Apply Traffic Engineering: Reroute traffic to reduce congestion
        - Tools Used: apply_configuration()
        - Expected Outcomes: Traffic rerouted; No alternate path; Partial improvement
        - Flow: If succeeds, go to step 7; if fails, go to step 6.

    6. Schedule Link Repair: Create ticket for link inspection
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Link inspection scheduled
        - Flow: Proceed to step 7.

    7. Verify Packet Loss Status: Monitor packet loss levels
        - Tools Used: verify_recovery()
        - Expected Outcomes: Packet loss resolved; Packet loss improved; Investigation ongoing
        - Flow: Proceed to step end.

    """,
    "transport_router_cpu_resolution": """
    Workflow: Router High CPU Resolution
    Domain: TRANSPORT | Problem Codes: TRN-006 | SLA: 60 minutes
    Description: Router CPU utilization troubleshooting

    1. Verify CPU Alarm: Confirm router CPU threshold exceeded
        - Tools Used: query_alarm()
        - Expected Outcomes: CPU elevated; CPU critical; CPU spikes
        - Flow: If succeeds, go to step 2; if fails, go to step 6.

    2. Check Router Status: Query router process and CPU breakdown
        - Tools Used: query_resource_health()
        - Expected Outcomes: Control plane high; Data plane high; Management high
        - Flow: If succeeds, go to step 3; if fails, go to step 5.

    3. Identify High CPU Process: Determine which process is consuming CPU
        - Tools Used: run_diagnostics()
        - Expected Outcomes: BGP reconvergence; OSPF SPF calculation; ACL processing; DoS attack suspected
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Apply Mitigation: Take action to reduce CPU load
        - Tools Used: execute_remote_action()
        - Expected Outcomes: Mitigation applied; Process stabilized; Root cause persists
        - Flow: If succeeds, go to step 7; if fails, go to step 5.

    5. Enable Control Plane Protection: Apply CoPP to protect control plane
        - Tools Used: apply_configuration()
        - Expected Outcomes: CoPP applied; CoPP already active; Rate limiting enabled
        - Flow: Proceed to step 6.

    6. Escalate if Needed: Create ticket for engineering review
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Engineering review scheduled
        - Flow: Proceed to step 7.
        - Note: This step is skippable if not applicable.

    7. Verify CPU Status: Monitor CPU recovery
        - Tools Used: verify_recovery()
        - Expected Outcomes: CPU normalized; CPU improved; CPU still elevated
        - Flow: Proceed to step end.

    """,
    "transport_routing_flap_resolution": """
    Workflow: Routing Protocol Flapping Resolution
    Domain: TRANSPORT | Problem Codes: TRN-008 | SLA: 30 minutes
    Description: BGP/OSPF/ISIS route flapping troubleshooting

    1. Verify Routing Alarm: Confirm routing protocol instability
        - Tools Used: query_alarm()
        - Expected Outcomes: BGP peer flapping; OSPF adjacency flapping; ISIS flapping
        - Flow: If succeeds, go to step 2; if fails, go to step 7.

    2. Check Protocol Status: Query routing protocol state
        - Tools Used: query_resource_health()
        - Expected Outcomes: Peer unstable; Hold timer expiry; Interface flapping
        - Flow: If succeeds, go to step 3; if fails, go to step 6.

    3. Analyze Protocol Logs: Review routing protocol event logs
        - Tools Used: inspect_logs()
        - Expected Outcomes: CPU issue indicated; Interface issue; Remote peer issue
        - Flow: If succeeds, go to step 4; if fails, go to step 5.

    4. Check Underlying Connectivity: Verify physical/logical path to peer
        - Tools Used: test_connectivity()
        - Expected Outcomes: Path stable; Path intermittent; Path down
        - Flow: If succeeds, go to step 5; if fails, go to step 6.

    5. Apply Route Dampening: Enable route dampening to stabilize
        - Tools Used: apply_configuration()
        - Expected Outcomes: Dampening enabled; Routing stabilizing
        - Flow: If succeeds, go to step 8; if fails, go to step 6.

    6. Adjust Timer Settings: Modify keepalive/hold timers
        - Tools Used: apply_configuration()
        - Expected Outcomes: Timers adjusted; Stability improved
        - Flow: If succeeds, go to step 8; if fails, go to step 7.

    7. Escalate to Network Engineering: Create urgent ticket for routing investigation
        - Tools Used: create_trouble_ticket()
        - Expected Outcomes: Engineering team notified
        - Flow: Proceed to step 8.

    8. Verify Routing Stability: Monitor routing protocol state
        - Tools Used: verify_recovery()
        - Expected Outcomes: Routing stable; Routing improving; Investigation ongoing
        - Flow: Proceed to step end.

    """,
}


DEFAULT_REASONING_PROCESS = WORKFLOW_REASONING_PROCESSES["ran_cell_site_down_recovery"]


def get_reasoning_process_for_fault_category(fault_category: str) -> str:
    """Return reasoning process text for a given fault_category (workflow ID)."""
    if fault_category is None or str(fault_category).strip() in ("", "nan", "None"):
        return DEFAULT_REASONING_PROCESS
    fc = str(fault_category).strip()
    return WORKFLOW_REASONING_PROCESSES.get(fc, DEFAULT_REASONING_PROCESS)
